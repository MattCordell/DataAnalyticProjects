{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install --upgrade pip\n!pip install fhir.resources\n#https://mybinder.org/\n#https://realpython.com/python-json/\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import requests\n\nendpoint= \"https://ontoserver.csiro.au/stu3-latest\"\nvalueSetExpand=\"/ValueSet/$expand?url=http://snomed.info/sct?fhir_vs=\" #should be less/break down\nexpand_API=endpoint+valueSetExpand\n\nmenagerie=[]\n#List of simple \"animal\" tuples\nmenagerie.append((406675000,'Crocodile'))\nmenagerie.append((33612001,'Dolphin'))\nmenagerie.append((12978006,'Goldfish'))\nmenagerie.append((395556009,'Platypus'))\nmenagerie.append((9354008,'Zebra'))\nmenagerie.append((57013002,'Koala'))\nmenagerie.append((18875000,'Cobra'))\nmenagerie.append((46783000,'Wallaby'))\n\n#Some classes to play with\neclClasses=[]\neclClasses.append(('ecl/<388002008','Monotremes'))\neclClasses.append(('ecl/<388006006','Marsupials'))\neclClasses.append(('ecl/<387976007','Mammals'))\neclClasses.append(('ecl/<90580008','Fish'))\neclClasses.append(('ecl/<107241004','Reptiles'))\n\nprint('classes and buckets created')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#retreive all the codes in each valueset expansion.\n#Store as a hashSet for O(1) lookup.\n\n#convert the respose into a VS object\nfrom fhir.resources.valueset import ValueSet \n\nbuckets=[]\n\nfor ecl in eclClasses:\n    response=requests.get(expand_API+ecl[0])\n    j=response.json()\n    vs=ValueSet(j)\n    #add every code to set()\n    newSet=set()\n    for e in vs.expansion.contains:          \n        newSet.add(int(e.code))\n    #add a \"bucket\" tuple with the name and set\n    buckets.append((ecl[1],newSet))\n    #200 works. However, if set is too big, pagination needs to happen\n    print(response.status_code,' ',ecl[1],' bucket created')\n\nprint('all buckets have been created')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#cycle through the buckets and list all the animals that can sit in that bucket\nfor bucket in buckets:\n    print(bucket[0])\n    for animal in menagerie:\n        if animal[0] in bucket[1]:\n            print('\\t',animal[1])\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#so what if we only want each animal in a single bucket?\n#One option is to ensure our buckets are in priority order, and remove the animal once it's been classified\n# O(m*n)\n\ntempAnimals = menagerie.copy()\n\n#cycle through the buckets and list all the animals that can sit in that bucket\nfor bucket in buckets:\n    print(bucket[0])\n    for animal in tempAnimals:        \n        if animal[0] in bucket[1]:\n            print('\\t',animal[1])\n            tempAnimals.remove(animal)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#OR\n#cycle animals first, attempting to classify each one. And break once classified.\n#O(n*m)\ntempAnimals = menagerie.copy()\nfor animal in tempAnimals:\n    for bucket in buckets:\n        if  animal[0] in bucket[1]:\n            print(animal[1],' is in ',bucket[0])\n            break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#OR a third approach is to actually populate the buckets under the requirements they be disjoint.\n# by populating our buckets only with contain animals that have not yet \"bucketed\" already\n\n#Super Class for all animals\nAnimals=('ecl/<387961004','Animals')\n\nresponse=requests.get(expand_API+Animals[0])\nj=response.json()\nvs=ValueSet(j)\n#add every code to set()\nnewSet=set()\nfor e in vs.expansion.contains:          \n    newSet.add(int(e.code))\n#SuperSet containing all available animals\nAvailableAnimals=(Animals[1],newSet)\n\n#now we repopulate our buckets\nbuckets=[]\n\nfor ecl in eclClasses:\n    response=requests.get(expand_API+ecl[0])\n    j=response.json()\n    vs=ValueSet(j)\n    #add every code to set()\n    newSet=set()\n    for e in vs.expansion.contains:          \n        newSet.add(int(e.code))\n    #limit newSet to those also in AvailableAnimals\n    newSet=newSet.intersection(AvailableAnimals[1])\n    #remove this newSet from AvailableAnimals\n    AvailableAnimals[1].difference_update(newSet)\n    \n    buckets.append((ecl[1],newSet))\n    #200 works. However, if set is too big, pagination needs to happen\n    print(response.status_code,' ',ecl[1],' bucket created')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cycle through the buckets and list all the animals that can sit in that bucket\nfor bucket in buckets:\n    print(bucket[0])\n    for animal in menagerie:\n        if animal[0] in bucket[1]:\n            print('\\t',animal[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#All these methods are still O(n*m) performance.\n#Worst case must always cycle through every bucket (m) and then every item in menagerie (n)\n#vectors would probably improve performance. Storing results as a matrix.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}